"""
é˜¿é‡Œäº‘åƒé—® API è¿æ¥æµ‹è¯•è„šæœ¬
"""

import os
import yaml

def test_qwen_connection():
    """æµ‹è¯•é˜¿é‡Œäº‘åƒé—® API è¿æ¥"""
    
    # 1. åƒé—®ä¸éœ€è¦ä»£ç†ï¼ˆé˜¿é‡Œäº‘å›½å†…/å›½é™…æœåŠ¡ï¼‰
    # æ¸…é™¤å¯èƒ½å­˜åœ¨çš„ä»£ç†è®¾ç½®
    for key in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']:
        if key in os.environ:
            del os.environ[key]
    print("ğŸŒ ä½¿ç”¨é˜¿é‡Œäº‘ DashScope APIï¼ˆæ— éœ€ä»£ç†ï¼‰")
    
    # 2. æ£€æŸ¥ openai åº“æ˜¯å¦å®‰è£…
    try:
        import openai
        print(f"âœ… openai åº“å·²å®‰è£…ï¼Œç‰ˆæœ¬: {openai.__version__}")
    except ImportError:
        print("âŒ openai åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install openai")
        return False
    
    # 3. ä»é…ç½®æ–‡ä»¶è¯»å–é…ç½®
    config_path = "configs/kuka_six_bricks.yaml"
    api_key = None
    model = "qwen-plus"
    base_url = "https://dashscope-intl.aliyuncs.com/compatible-mode/v1"  # å›½é™…ç‰ˆé»˜è®¤
    
    if os.path.exists(config_path):
        with open(config_path, 'r') as f:
            cfg = yaml.safe_load(f)
            llm_cfg = cfg.get('llm', {})
            api_key = llm_cfg.get('api_key')
            model = llm_cfg.get('model', 'qwen-plus')
            base_url = llm_cfg.get('base_url', base_url)
            print(f"ğŸ“„ ä»é…ç½®æ–‡ä»¶è¯»å–:")
            print(f"   model={model}")
            print(f"   base_url={base_url}")
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ° API Keyï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®")
        return False
    
    # éšè—æ˜¾ç¤º API Key
    masked_key = api_key[:8] + "..." + api_key[-4:] if len(api_key) > 12 else "***"
    print(f"ğŸ”‘ ä½¿ç”¨ API Key: {masked_key}")
    
    # 4. æµ‹è¯•è¿æ¥
    print("\nğŸ”„ æ­£åœ¨æµ‹è¯•åƒé—® API è¿æ¥...")
    
    try:
        from openai import OpenAI
        
        # å…³é”®ï¼šå¿…é¡»è®¾ç½® base_urlï¼
        client = OpenAI(
            api_key=api_key,
            base_url=base_url  # æŒ‡å‘é˜¿é‡Œäº‘ç«¯ç‚¹
        )
        
        # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "Say 'Hello, connection test successful!' in one short sentence."}
            ],
            max_tokens=50,
            temperature=0.0
        )
        
        reply = response.choices[0].message.content
        print(f"\nâœ… API è¿æ¥æˆåŠŸ!")
        print(f"ğŸ“¨ æ¨¡å‹å›å¤: {reply}")
        print(f"ğŸ“Š ä½¿ç”¨çš„æ¨¡å‹: {response.model}")
        if response.usage:
            print(f"ğŸ“Š Token ä½¿ç”¨: prompt={response.usage.prompt_tokens}, completion={response.usage.completion_tokens}")
        
        return True
        
    except openai.AuthenticationError as e:
        print(f"\nâŒ API Key è®¤è¯å¤±è´¥: {e}")
        print("   è¯·æ£€æŸ¥ DashScope API Key æ˜¯å¦æ­£ç¡®")
        return False
        
    except openai.APIConnectionError as e:
        print(f"\nâŒ API è¿æ¥é”™è¯¯: {e}")
        print("   è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
        return False
        
    except Exception as e:
        print(f"\nâŒ æœªçŸ¥é”™è¯¯: {type(e).__name__}: {e}")
        return False


if __name__ == "__main__":
    print("="*50)
    print("é˜¿é‡Œäº‘åƒé—® API è¿æ¥æµ‹è¯•")
    print("="*50 + "\n")
    
    success = test_qwen_connection()
    
    print("\n" + "="*50)
    if success:
        print("ğŸ‰ æµ‹è¯•å®Œæˆï¼Œåƒé—® API è¿æ¥æ­£å¸¸!")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºè§£å†³é—®é¢˜")
    print("="*50)