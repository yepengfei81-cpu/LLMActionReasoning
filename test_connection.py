"""
OpenAI API è¿æ¥æµ‹è¯•è„šæœ¬
"""

import os
import yaml

def test_openai_connection():
    """æµ‹è¯• OpenAI API è¿æ¥"""
    
    # 1. è®¾ç½®ä»£ç†ï¼ˆä½¿ç”¨ä½ çš„ä»£ç†ç«¯å£ 7897ï¼‰
    proxy_url = "http://127.0.0.1:7897"
    os.environ['HTTP_PROXY'] = proxy_url
    os.environ['HTTPS_PROXY'] = proxy_url
    os.environ['http_proxy'] = proxy_url
    os.environ['https_proxy'] = proxy_url
    print(f"ğŸŒ ä½¿ç”¨ä»£ç†: {proxy_url}")
    
    # 2. æ£€æŸ¥ openai åº“æ˜¯å¦å®‰è£…
    try:
        import openai
        print(f"âœ… openai åº“å·²å®‰è£…ï¼Œç‰ˆæœ¬: {openai.__version__}")
    except ImportError:
        print("âŒ openai åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install openai")
        return False
    
    # 3. ä»é…ç½®æ–‡ä»¶è¯»å– API Key
    config_path = "configs/kuka_six_bricks.yaml"
    api_key = None
    model = "gpt-4o-mini"
    
    if os.path.exists(config_path):
        with open(config_path, 'r') as f:
            cfg = yaml.safe_load(f)
            llm_cfg = cfg.get('llm', {})
            api_key = llm_cfg.get('api_key')
            model = llm_cfg.get('model', 'gpt-4o-mini')
            print(f"ğŸ“„ ä»é…ç½®æ–‡ä»¶è¯»å–: model={model}")
    
    # ä¹Ÿæ£€æŸ¥ç¯å¢ƒå˜é‡
    env_api_key = os.environ.get('OPENAI_API_KEY')
    if env_api_key:
        print("ğŸ“„ æ£€æµ‹åˆ°ç¯å¢ƒå˜é‡ OPENAI_API_KEY")
        api_key = env_api_key
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ° API Keyï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ä¸­è®¾ç½®")
        return False
    
    # éšè—æ˜¾ç¤º API Keyï¼ˆåªæ˜¾ç¤ºå‰8ä½å’Œå4ä½ï¼‰
    masked_key = api_key[:8] + "..." + api_key[-4:] if len(api_key) > 12 else "***"
    print(f"ğŸ”‘ ä½¿ç”¨ API Key: {masked_key}")
    
    # 4. æµ‹è¯•è¿æ¥
    print("\nğŸ”„ æ­£åœ¨æµ‹è¯• API è¿æ¥...")
    
    try:
        from openai import OpenAI
        
        client = OpenAI(api_key=api_key)
        
        # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "user", "content": "Say 'Hello, connection test successful!' in one short sentence."}
            ],
            max_tokens=50,
            temperature=0.0
        )
        
        reply = response.choices[0].message.content
        print(f"\nâœ… API è¿æ¥æˆåŠŸ!")
        print(f"ğŸ“¨ æ¨¡å‹å›å¤: {reply}")
        print(f"ğŸ“Š ä½¿ç”¨çš„æ¨¡å‹: {response.model}")
        print(f"ğŸ“Š Token ä½¿ç”¨: prompt={response.usage.prompt_tokens}, completion={response.usage.completion_tokens}")
        
        return True
        
    except openai.AuthenticationError as e:
        print(f"\nâŒ API Key è®¤è¯å¤±è´¥: {e}")
        print("   è¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®ã€æ˜¯å¦è¿‡æœŸ")
        return False
        
    except openai.RateLimitError as e:
        print(f"\nâŒ API è¯·æ±‚é¢‘ç‡é™åˆ¶: {e}")
        print("   å¯èƒ½æ˜¯é…é¢ç”¨å°½æˆ–è¯·æ±‚è¿‡äºé¢‘ç¹")
        return False
        
    except openai.APIConnectionError as e:
        print(f"\nâŒ API è¿æ¥é”™è¯¯: {e}")
        print("   å¯èƒ½çš„åŸå› :")
        print("   1. ä»£ç†ç«¯å£ 7897 æ˜¯å¦æ­£ç¡®ï¼Ÿ")
        print("   2. ä»£ç†è½¯ä»¶æ˜¯å¦æ­£å¸¸è¿è¡Œï¼Ÿ")
        print("   3. å°è¯•å…¶ä»–ç«¯å£å¦‚ 7890")
        return False
        
    except Exception as e:
        print(f"\nâŒ æœªçŸ¥é”™è¯¯: {type(e).__name__}: {e}")
        return False


if __name__ == "__main__":
    print("="*50)
    print("OpenAI API è¿æ¥æµ‹è¯•")
    print("="*50 + "\n")
    
    success = test_openai_connection()
    
    print("\n" + "="*50)
    if success:
        print("ğŸ‰ æµ‹è¯•å®Œæˆï¼ŒAPI è¿æ¥æ­£å¸¸!")
        print("\nğŸ’¡ åœ¨è¿è¡Œä¸»ç¨‹åºæ—¶ï¼Œè¯·å…ˆè®¾ç½®ç¯å¢ƒå˜é‡:")
        print("   export HTTP_PROXY=http://127.0.0.1:7897")
        print("   export HTTPS_PROXY=http://127.0.0.1:7897")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºè§£å†³é—®é¢˜")
    print("="*50)